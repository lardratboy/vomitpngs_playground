{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyP7jtEsL3jJzV5PT33HNgaZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lardratboy/vomitpngs_playground/blob/main/vomitpngs_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VOMIT PNG's 1.0 - CHUNKY DATA EXPLORER\n",
        "\n",
        "This tool is able to dump IFF-like chunk files (4 byte ascii id, followed by a big endian 32 bit integer, followed by the contained data. Each chunk header includes the size of data and the size of the header, making this slightly different than standard IFF/RIFF chunks)."
      ],
      "metadata": {
        "id": "i8e-mmVMe6xH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0. (optional) connect to google drive"
      ],
      "metadata": {
        "id": "aE6tYs-TuE2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mount = False #@param {type:\"boolean\"}\n",
        "if mount:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zIU3tBWxuEet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. Setup what you want to dump and where to put it"
      ],
      "metadata": {
        "id": "_rf0rLOSt5k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_filename = '/content/something.he1' #@param {type:\"string\"}\n",
        "test_output_format = '%4s_%08d.png' #@param {type:\"string\"}\n",
        "test_xor_key = 105 #@param {type:\"number\"}\n",
        "test_page_width = 1024 #@param {type:\"number\"}\n",
        "test_page_height = 1024 #@param {type:\"number\"}\n",
        "test_bundle = True #@param {type:\"boolean\"}\n",
        "test_gray = False #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "ENpP45H2fI87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2. Define a rectangle packing system"
      ],
      "metadata": {
        "id": "n7lb848tZ5aU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://gist.github.com/lardratboy/847d8901f4ca60c70677f07f2edc4d66\n",
        "\n",
        "class Rect:\n",
        "\n",
        "    def __init__(self, left, top, right, bottom):\n",
        "\n",
        "        self.left = left\n",
        "        self.top = top\n",
        "        self.right = right\n",
        "        self.bottom = bottom\n",
        "\n",
        "    def width(self):\n",
        "        return self.right - self.left\n",
        "\n",
        "    def height(self):\n",
        "        return self.bottom - self.top\n",
        "\n",
        "class Page:\n",
        "\n",
        "    def __init__(self, width, height):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.free_rects = [ Rect( 0, 0, width, height ) ]\n",
        "        self.occupied_rects = []\n",
        "\n",
        "    def external_clipped_rects( a, b ):\n",
        "        top, bottom = a.top, a.bottom\n",
        "        if ( a.top < b.top ):\n",
        "            top = b.top\n",
        "            yield Rect( a.left, a.top, a.right, b.top )\n",
        "        if ( a.bottom > b.bottom ):\n",
        "            bottom = b.bottom\n",
        "            yield Rect( a.left, b.bottom, a.right, a.bottom )\n",
        "        if ( a.left < b.left ):\n",
        "            yield Rect( a.left, top, b.left, bottom )\n",
        "        if ( a.right > b.right ):\n",
        "            yield Rect( b.right, top, a.right, bottom )\n",
        "\n",
        "    def insert( self, width, height ):\n",
        "        for free_rect in self.free_rects:\n",
        "            if free_rect.width() < width or free_rect.height() < height: continue\n",
        "            rect = Rect( free_rect.left, free_rect.top, free_rect.left + width, free_rect.top + height )\n",
        "            self.occupied_rects.append( rect )\n",
        "            self.free_rects.remove( free_rect )\n",
        "            free_count = len( self.free_rects )\n",
        "            for clipped_rect in Page.external_clipped_rects( free_rect, rect ):\n",
        "                self.free_rects.append( clipped_rect )\n",
        "            if free_count != len( self.free_rects ):\n",
        "                self.free_rects.sort( key=lambda x: (x.height()) )\n",
        "            return rect\n",
        "\n",
        "    def calculate_efficency( self ):\n",
        "        total_area = self.width * self.height\n",
        "        used_area = sum( [ rect.width() * rect.height() for rect in self.occupied_rects ] )\n",
        "        return used_area / total_area\n",
        "\n",
        "class Packer:\n",
        "\n",
        "    def __init__(self, width, height):\n",
        "        self.pages = [ Page( width, height ) ]\n",
        "        self.page_width = width\n",
        "        self.page_height = height\n",
        "\n",
        "    def insert( self, width, height ):\n",
        "        for page in self.pages:\n",
        "            rect = page.insert( width, height )\n",
        "            if rect: return page, rect\n",
        "        new_page = Page( self.page_width, self.page_height )\n",
        "        self.pages.append( new_page )\n",
        "        return new_page, new_page.insert( width, height )"
      ],
      "metadata": {
        "id": "ViVPoK7OZZEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3. Chunk collecting and parsing classes"
      ],
      "metadata": {
        "id": "oVjfwQlJaheS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io, struct, argparse, math\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DataChunkCollector:\n",
        "\n",
        "    def __init__( self, output_formatter = None, save_as_grayscale=False, bundle=False, page_width=1024, page_height=1024 ):\n",
        "        self.output_formatter = output_formatter\n",
        "        self.next_number = 1\n",
        "        self.save_as_grayscale = save_as_grayscale\n",
        "        self.save_png = None != output_formatter\n",
        "        self.bundle = bundle\n",
        "        self.images_by_types = {}\n",
        "        self.bundled_images = []\n",
        "        self.page_width = page_width\n",
        "        self.page_height = page_height\n",
        "\n",
        "    def collect( self, chunk ):\n",
        "\n",
        "        if not chunk.id in [ 'AWIZ', 'AKOS', 'SDAT', 'SOUN', 'DIGI', 'RMIM', 'COST', 'FORM' ]: return\n",
        "        actual_size = len(chunk.data)\n",
        "\n",
        "        if self.save_png:\n",
        "\n",
        "            filename = self.output_formatter % (chunk.id, self.next_number)\n",
        "            self.next_number += 1\n",
        "\n",
        "            if self.save_as_grayscale:\n",
        "\n",
        "                aligned_size = actual_size\n",
        "                side = math.floor( max( math.ceil(math.sqrt(aligned_size)), 1 ) )\n",
        "                dim = ( side, side )\n",
        "                storage = ( dim[0] * dim[1] )\n",
        "\n",
        "            else:\n",
        "\n",
        "                aligned_size = ((actual_size + 2) // 3)\n",
        "                side = math.floor( max( math.ceil(math.sqrt(aligned_size)), 1 ) )\n",
        "                dim = ( side, side, 3 )\n",
        "                storage = ( dim[0] * dim[1] * dim[2] )\n",
        "\n",
        "            nd = np.zeros(dim, dtype=np.uint8)\n",
        "            v1 = nd.reshape(storage,)\n",
        "            v1[0:actual_size] = list(chunk.data)\n",
        "            img = Image.fromarray( nd )\n",
        "\n",
        "            if self.bundle:\n",
        "\n",
        "                if not chunk.id in self.images_by_types: self.images_by_types[ chunk.id ] = []\n",
        "                img.chunk = chunk\n",
        "                self.images_by_types[ chunk.id ].append( img )\n",
        "\n",
        "            else:\n",
        "\n",
        "                img.save( filename )\n",
        "                del img\n",
        "\n",
        "            del nd\n",
        "\n",
        "    def save_bundles( self ):\n",
        "\n",
        "        if not self.bundle: return\n",
        "\n",
        "        packs = []\n",
        "\n",
        "        # pack images by type\n",
        "\n",
        "        for id in tqdm( self.images_by_types.keys() ):\n",
        "\n",
        "            self.images_by_types[ id ].sort( key=lambda x: x.height, reverse=True)\n",
        "\n",
        "            packer = Packer( self.page_width, self.page_width )\n",
        "            packs.append( packer )\n",
        "            packer.rects_by_image = {}\n",
        "            packer.id = id\n",
        "\n",
        "            for img in self.images_by_types[ id ]:\n",
        "                page, rect = packer.insert( img.width, img.height )\n",
        "                if not rect: print( f'ERROR:: failed to insert {img.width=}, {img.height=} ::ERROR' )\n",
        "                rect.img = img\n",
        "\n",
        "        # build and save bundles for each packer\n",
        "\n",
        "        for packer in packs:\n",
        "            for i, page in enumerate( packer.pages, 1 ):\n",
        "                canvas = Image.new( 'RGB', ( packer.page_width, packer.page_height ), color=(0,0,0) )\n",
        "                for rect in tqdm( page.occupied_rects ):\n",
        "                    canvas.paste( rect.img, ( rect.left, rect.top ) )\n",
        "                filename = self.output_formatter % (packer.id, i)\n",
        "                canvas.save( filename )\n",
        "                canvas.filename = filename\n",
        "                canvas.page = page\n",
        "                self.bundled_images.append( canvas )\n"
      ],
      "metadata": {
        "id": "3Ple0kuUYf2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main logic for traversing the nested chunks"
      ],
      "metadata": {
        "id": "BFYP3H9uYw1a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma909z7cY29d"
      },
      "outputs": [],
      "source": [
        "class Chunk:\n",
        "\n",
        "    def __init__( self, id, offset, depth=0 ):\n",
        "        self.id = id\n",
        "        self.offset = offset\n",
        "        self.depth = depth\n",
        "        self.children = []\n",
        "        self.data = None\n",
        "\n",
        "def skip_possible_garbage_data( input, chunk, remaining_data ):\n",
        "\n",
        "    if not chunk.id in [ 'DIGI' ]: return 0\n",
        "    start_offset = input.tell()\n",
        "    skipped = 0\n",
        "\n",
        "    while skipped < remaining_data:\n",
        "\n",
        "        try:\n",
        "            id = input.read( 4 ).decode( 'ascii' )\n",
        "            input.seek( start_offset + skipped )\n",
        "            return 0\n",
        "        except:\n",
        "            print( f'possible garbage trying to skip' )\n",
        "            skipped += 1\n",
        "\n",
        "        input.seek( start_offset + skipped )\n",
        "\n",
        "    return skipped\n",
        "\n",
        "def process_chunk( input, parent_chunk, remaining_data, depth = 0, collector = None, bundle = False ):\n",
        "\n",
        "    if None != parent_chunk.id and not parent_chunk.id in [ 'MULT', 'WRAP', 'TALK', 'TLKB', 'LECF', 'LFLF', 'SONG', 'NEST', 'RMDA', 'OBIM', 'ROOM' ]:\n",
        "\n",
        "        print( ' ' * depth + f'{parent_chunk.id} size={remaining_data}' )\n",
        "\n",
        "        input.seek( input.tell() - 8 )\n",
        "        parent_chunk.data = input.read( remaining_data + 8 )\n",
        "        if collector: collector.collect( parent_chunk )\n",
        "        return\n",
        "\n",
        "    print( ' ' * depth + f'processing {parent_chunk.id}' )\n",
        "\n",
        "    while 8 < remaining_data:\n",
        "\n",
        "        offset = input.tell()\n",
        "        id = input.read( 4 ).decode( 'ascii' )\n",
        "        size = struct.unpack( '>I', input.read( 4 ))[0]\n",
        "        chunk = Chunk( id, offset, depth=depth )\n",
        "        parent_chunk.children.append( chunk )\n",
        "        process_chunk( input, chunk, size - 8, depth + 1, collector=collector, bundle=bundle )\n",
        "        remaining_data -= size\n",
        "        skipped = skip_possible_garbage_data( input, chunk, remaining_data )\n",
        "        remaining_data -= skipped\n",
        "\n",
        "def parse_chunks_for_file( filename, xor_key = None, collector = None, bundle = False):\n",
        "\n",
        "    with open(filename,'rb') as f: raw_data = f.read()\n",
        "    if xor_key: raw_data = bytes( a ^ xor_key for a in raw_data )\n",
        "    input = io.BytesIO( raw_data )\n",
        "    root_chunk = Chunk( None, input.tell() )\n",
        "    process_chunk( input, root_chunk, len( raw_data ), collector=collector, bundle=bundle )\n",
        "    return root_chunk\n",
        "\n",
        "def inner_main(args):\n",
        "\n",
        "    collector = DataChunkCollector( args.png, save_as_grayscale=args.gray, bundle=args.bundle, page_width=args.page_width, page_height=args.page_height )\n",
        "    file_chunks = parse_chunks_for_file( args.filename, xor_key=args.xor, collector=collector, bundle=args.bundle )\n",
        "    collector.save_bundles()\n",
        "    return collector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4. Perform the operation by using the test settings from above"
      ],
      "metadata": {
        "id": "QrACIJqTP4Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class args_helper:\n",
        "  def __init__( self, filename, gray, png, xor, bundle, page_width, page_height ):\n",
        "    self.filename = filename\n",
        "    self.gray = gray\n",
        "    self.png = png\n",
        "    self.xor = xor\n",
        "    self.bundle = bundle\n",
        "    self.page_width = page_width\n",
        "    self.page_height = page_height\n",
        "\n",
        "collector = inner_main( args_helper(\n",
        "    filename=test_filename, gray=test_gray, png=test_output_format, xor=test_xor_key,\n",
        "    bundle=test_bundle, page_width=test_page_width, page_height=test_page_height ) )"
      ],
      "metadata": {
        "id": "iCDMKNFkfnV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5. display the page output filenames and the packing efficency\n"
      ],
      "metadata": {
        "id": "QQfSSUm4rER6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total number of bundles = {len(collector.bundled_images)}')\n",
        "\n",
        "for i, canvas in enumerate( collector.bundled_images ):\n",
        "  print( f'page {canvas.filename} efficency={canvas.page.calculate_efficency()}')"
      ],
      "metadata": {
        "id": "dSH09Jbmp_db"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}